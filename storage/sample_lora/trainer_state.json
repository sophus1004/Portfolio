{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 1.8969532251358032,
      "learning_rate": 9.990133642141359e-06,
      "loss": 1.672,
      "step": 1
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0587079524993896,
      "learning_rate": 9.960573506572391e-06,
      "loss": 2.1921,
      "step": 2
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6932013034820557,
      "learning_rate": 9.911436253643445e-06,
      "loss": 2.2607,
      "step": 3
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.244009256362915,
      "learning_rate": 9.842915805643156e-06,
      "loss": 3.0952,
      "step": 4
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.858518362045288,
      "learning_rate": 9.755282581475769e-06,
      "loss": 2.481,
      "step": 5
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2309861183166504,
      "learning_rate": 9.648882429441258e-06,
      "loss": 2.8539,
      "step": 6
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6921695470809937,
      "learning_rate": 9.524135262330098e-06,
      "loss": 2.2101,
      "step": 7
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.937907338142395,
      "learning_rate": 9.381533400219319e-06,
      "loss": 2.1342,
      "step": 8
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0830652713775635,
      "learning_rate": 9.221639627510076e-06,
      "loss": 1.7572,
      "step": 9
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.528562068939209,
      "learning_rate": 9.045084971874738e-06,
      "loss": 2.2297,
      "step": 10
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.530845046043396,
      "learning_rate": 8.852566213878947e-06,
      "loss": 1.9696,
      "step": 11
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.8600057363510132,
      "learning_rate": 8.644843137107058e-06,
      "loss": 2.008,
      "step": 12
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1306253671646118,
      "learning_rate": 8.422735529643445e-06,
      "loss": 1.6722,
      "step": 13
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.187612533569336,
      "learning_rate": 8.18711994874345e-06,
      "loss": 3.138,
      "step": 14
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.6972272396087646,
      "learning_rate": 7.938926261462366e-06,
      "loss": 2.4185,
      "step": 15
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9835187196731567,
      "learning_rate": 7.679133974894984e-06,
      "loss": 2.2052,
      "step": 16
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8601258993148804,
      "learning_rate": 7.408768370508577e-06,
      "loss": 2.4788,
      "step": 17
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.668672800064087,
      "learning_rate": 7.128896457825364e-06,
      "loss": 1.5051,
      "step": 18
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.312312364578247,
      "learning_rate": 6.840622763423391e-06,
      "loss": 2.1558,
      "step": 19
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.011853814125061,
      "learning_rate": 6.545084971874738e-06,
      "loss": 2.3828,
      "step": 20
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3774657249450684,
      "learning_rate": 6.243449435824276e-06,
      "loss": 2.4506,
      "step": 21
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3370089530944824,
      "learning_rate": 5.936906572928625e-06,
      "loss": 1.8263,
      "step": 22
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.0103204250335693,
      "learning_rate": 5.626666167821522e-06,
      "loss": 2.3532,
      "step": 23
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.611607313156128,
      "learning_rate": 5.3139525976465675e-06,
      "loss": 1.823,
      "step": 24
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7497185468673706,
      "learning_rate": 5e-06,
      "loss": 2.1382,
      "step": 25
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.75900137424469,
      "learning_rate": 4.686047402353433e-06,
      "loss": 1.8764,
      "step": 26
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.183265209197998,
      "learning_rate": 4.373333832178478e-06,
      "loss": 1.7376,
      "step": 27
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0478005409240723,
      "learning_rate": 4.063093427071376e-06,
      "loss": 2.4289,
      "step": 28
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4202079772949219,
      "learning_rate": 3.756550564175727e-06,
      "loss": 2.0977,
      "step": 29
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5271172523498535,
      "learning_rate": 3.4549150281252635e-06,
      "loss": 1.8185,
      "step": 30
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5731688737869263,
      "learning_rate": 3.1593772365766107e-06,
      "loss": 1.8461,
      "step": 31
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4657074213027954,
      "learning_rate": 2.871103542174637e-06,
      "loss": 1.9616,
      "step": 32
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.286980152130127,
      "learning_rate": 2.5912316294914232e-06,
      "loss": 1.803,
      "step": 33
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0067479610443115,
      "learning_rate": 2.320866025105016e-06,
      "loss": 2.1928,
      "step": 34
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.122337818145752,
      "learning_rate": 2.061073738537635e-06,
      "loss": 1.9645,
      "step": 35
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.261380910873413,
      "learning_rate": 1.8128800512565514e-06,
      "loss": 2.049,
      "step": 36
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3998744487762451,
      "learning_rate": 1.5772644703565564e-06,
      "loss": 1.3485,
      "step": 37
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0676991939544678,
      "learning_rate": 1.3551568628929434e-06,
      "loss": 2.1077,
      "step": 38
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.6441757082939148,
      "learning_rate": 1.1474337861210543e-06,
      "loss": 0.5174,
      "step": 39
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8059241771697998,
      "learning_rate": 9.549150281252633e-07,
      "loss": 2.3019,
      "step": 40
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1645374298095703,
      "learning_rate": 7.783603724899258e-07,
      "loss": 1.7999,
      "step": 41
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9560496211051941,
      "learning_rate": 6.184665997806832e-07,
      "loss": 2.6377,
      "step": 42
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6929259300231934,
      "learning_rate": 4.758647376699033e-07,
      "loss": 2.5262,
      "step": 43
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4684414863586426,
      "learning_rate": 3.511175705587433e-07,
      "loss": 1.8099,
      "step": 44
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.1311140060424805,
      "learning_rate": 2.447174185242324e-07,
      "loss": 1.8982,
      "step": 45
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9765599966049194,
      "learning_rate": 1.5708419435684463e-07,
      "loss": 1.7305,
      "step": 46
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.782759189605713,
      "learning_rate": 8.856374635655696e-08,
      "loss": 1.9508,
      "step": 47
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2731086015701294,
      "learning_rate": 3.9426493427611177e-08,
      "loss": 1.7628,
      "step": 48
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4679204225540161,
      "learning_rate": 9.866357858642206e-09,
      "loss": 1.9927,
      "step": 49
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.715561866760254,
      "learning_rate": 0.0,
      "loss": 2.1357,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 50,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 163562653731840.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
